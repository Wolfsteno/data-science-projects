{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aprendizaje Supervisado (Microsoft Malware Prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`Objetivo`: Estimar la probabilidad de que un equipo con Windows se infecte con malware, utilizando las propiedades del sistema."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Instalacion y configuracion de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib.util\n",
    "import subprocess\n",
    "\n",
    "def install_if_missing(package):\n",
    "    if importlib.util.find_spec(package) is None:\n",
    "        print(f\"Instalando {package}...\")\n",
    "        subprocess.check_call([\"pip\", \"install\", package])\n",
    "    else:\n",
    "        print(f\"{package} ya está instalado.\")\n",
    "\n",
    "# Lista de paquetes necesarios\n",
    "required_packages = [\"pandas\",\"numpy\",\"matplotlib\",\"seaborn\",\"scikit-learn\", \"rich\"]\n",
    "\n",
    "# Verificar e instalar los paquetes necesarios\n",
    "for package in required_packages:\n",
    "    install_if_missing(package)\n",
    "\n",
    "print(\"Instalación de paquetes completada.\")\n",
    "\n",
    "# El paquete rich nos ayudara a mostrar de una forma mas atractiva los \"print\"\n",
    "from rich.console import Console\n",
    "console = Console()\n",
    "\n",
    "# Y esta otra herramienta nos ayudara a visualizar mejor los datos devueltos en los \"print\"\n",
    "from rich.table import Table\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_rows', None)  # Muestra todas las filas\n",
    "pd.set_option('display.max_columns', None)  # Muestra todas las columnas\n",
    "pd.set_option('display.float_format', '{:.4f}'.format) # Esta opcion los valores float se muestren sin notacion cientifica.\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Descarga y carga del data frame\n",
    "En este paso, se descarga el archivo de datos desde un enlace proporcionado y se carga en un DataFrame de pandas para su posterior análisis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configura el origen de los datos según tu necesidad:\n",
    "\n",
    "# Para leer el archivo desde una URL remota:\n",
    "# url = \"https://www.dropbox.com/scl/fi/uvv7j1bragzqkz9zwyvj0/sample_mmp.csv?rlkey=i0mlaxzq6e3blblfu9mhrdpsm&e=1&dl=1\"\n",
    "# df = pd.read_csv(url)\n",
    "\n",
    "# Para leer el archivo desde una ubicación local:\n",
    "df = pd.read_csv(\"sample_mmp.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Preprocesamiento\n",
    "En esta sección, realizaremos un análisis preliminar y definiremos las variables y métodos necesarios para la limpieza y transformación de los datos. Esto incluirá el tratamiento de valores nulos, la codificación de variables y el escalado, preparando así los datos para un análisis más efectivo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Primero haremos una exploracion basica de los datos y sacaremos conclusiones y decidiremos cuales funcions nos haran falta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum() / len(df) * 100\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tras analizar los datos y examinar las columnas individualmente en notebooks personales, organizamos su distribución de manera equitativa para que cada miembro del equipo tuviera un número exacto y balanceado de columnas:\n",
    "``` python\n",
    "fran_columns = list(df.columns[0:21])\n",
    "ignacio_columns = list(df.columns[21:42])\n",
    "marc_columns = list(df.columns[42:63])\n",
    "alvaro_columns = list(df.columns[63:85])\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como equipo, hemos decidido implementar los siguientes métodos para gestionar los datos de forma más estructurada y metódica."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `drop_unique_columns()`\n",
    "Detecta y elimina columnas en las que cada valor es único (número de valores únicos igual al número de filas), ya que probablemente se trate de índices internos que no aportan información útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_unique_columns(df):\n",
    "    console = Console()\n",
    "    total_rows = len(df)\n",
    "    cols_to_drop = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        if df[col].nunique() == total_rows:\n",
    "            cols_to_drop.append(col)\n",
    "    \n",
    "    if cols_to_drop:\n",
    "        console.print(f\"[bold green]Columnas eliminadas por tener valores únicos en cada fila:[/bold green] {cols_to_drop}\")\n",
    "        df = df.drop(columns=cols_to_drop)\n",
    "    else:\n",
    "        console.print(\"[bold yellow]No se encontraron columnas con valores únicos en cada fila.[/bold yellow]\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `classify_columns()`\n",
    "Automatiza la clasificación por tipo de datos para aplicar tratamientos específicos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_columns(df):\n",
    "    boolean_cols = df.select_dtypes(include=['bool']).columns.tolist()\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    string_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    console.print(\"[bold cyan]Clasificación de columnas:[/bold cyan]\")\n",
    "    console.print(f\"[green]Booleanas:[/green] {boolean_cols}\")\n",
    "    console.print(f\"[green]Numéricas:[/green] {numeric_cols}\")\n",
    "    console.print(f\"[green]Cadenas de texto:[/green] {string_cols}\")\n",
    "    \n",
    "    return boolean_cols, numeric_cols, string_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `drop_columns_with_nulls(df, threshold=0.5)`\n",
    "Elimina columnas con más del 50% de valores nulos para evitar ruido."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_columns_with_nulls(df, threshold=0.5):\n",
    "    null_percent = df.isnull().mean() * 100\n",
    "\n",
    "    table = Table(title=\"Porcentaje de valores nulos por columna\")\n",
    "    table.add_column(\"Columna\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Porcentaje\", style=\"yellow\")\n",
    "\n",
    "    for col, val in null_percent.sort_values(ascending=False).items():\n",
    "        table.add_row(str(col), f\"{val:.2f}%\")\n",
    "\n",
    "    console.print(table)\n",
    "\n",
    "    cols_to_drop = df.isnull().mean()[df.isnull().mean() > threshold].index.tolist()\n",
    "    console.print(f\"\\n[bold red]Columnas eliminadas por alto porcentaje de nulos (>{threshold*100}%):[/bold red] {cols_to_drop}\")\n",
    "\n",
    "    df_clean = df.drop(columns=cols_to_drop)\n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `drop_rows_with_few_nulls(df, threshold=0.01)`\n",
    "Elimina filas con valores nulos en columnas donde los nulos representan menos del 1% de las observaciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_rows_with_few_nulls(df, threshold=0.01):\n",
    "    null_percent = df.isnull().mean() * 100\n",
    "    table = Table(title=\"Porcentaje de valores nulos por columna\")\n",
    "    table.add_column(\"Columna\", style=\"cyan\", no_wrap=True)\n",
    "    table.add_column(\"Porcentaje\", style=\"yellow\")\n",
    "    \n",
    "    for col, val in null_percent.sort_values(ascending=False).items():\n",
    "        table.add_row(str(col), f\"{round(val)}%\")\n",
    "    \n",
    "    console.print(table)\n",
    "    \n",
    "    cols_to_clean = null_percent[null_percent < threshold * 100].index.tolist()\n",
    "    console.print(f\"\\n[bold green]Columnas con menos del {threshold*100}% de nulos:[/bold green] {cols_to_clean}\")\n",
    "    \n",
    "    df_clean = df.dropna(subset=cols_to_clean)\n",
    "    console.print(\"\\n[bold red]Se eliminaron las filas que contenían nulos en las columnas mencionadas.[/bold red]\")\n",
    "    \n",
    "    return df_clean\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `fill_nulls_in_column(df, column, strategy=None)`\n",
    "Rellena los valores nulos de la columna especificada utilizando una estrategia de imputación que minimice el impacto en el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_nulls_in_column(df, column, strategy=None):\n",
    "    # Verificar que la columna exista\n",
    "    if column not in df.columns:\n",
    "        console.print(f\"[bold red]La columna '{column}' no existe en el DataFrame.[/bold red]\")\n",
    "        return df\n",
    "\n",
    "    # Mostrar información de los valores nulos en la columna\n",
    "    total = len(df[column])\n",
    "    missing = df[column].isnull().sum()\n",
    "    percent_missing = (missing / total) * 100\n",
    "    console.print(f\"[bold cyan]La columna '{column}' tiene {missing} valores nulos de {total} ({percent_missing:.2f}%).[/bold cyan]\")\n",
    "\n",
    "    # Seleccionar estrategia por defecto según el tipo de dato, si no se especifica\n",
    "    if strategy is None:\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            strategy = 'median'\n",
    "        else:\n",
    "            strategy = 'mode'\n",
    "    \n",
    "    # Aplicar la estrategia de imputación\n",
    "    if strategy == 'median':\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            median_value = df[column].median()\n",
    "            df[column] = df[column].fillna(median_value)\n",
    "            console.print(f\"[bold green]Se han imputado los nulos de la columna '{column}' con la mediana: {median_value}[/bold green]\")\n",
    "        else:\n",
    "            console.print(f\"[bold red]La estrategia 'median' no es adecuada para la columna '{column}' de tipo {df[column].dtype}.[/bold red]\")\n",
    "    elif strategy == 'mean':\n",
    "        if pd.api.types.is_numeric_dtype(df[column]):\n",
    "            mean_value = df[column].mean()\n",
    "            df[column] = df[column].fillna(mean_value)\n",
    "            console.print(f\"[bold green]Se han imputado los nulos de la columna '{column}' con la media: {mean_value}[/bold green]\")\n",
    "        else:\n",
    "            console.print(f\"[bold red]La estrategia 'mean' no es adecuada para la columna '{column}' de tipo {df[column].dtype}.[/bold red]\")\n",
    "    elif strategy == 'mode':\n",
    "        mode_series = df[column].mode()\n",
    "        if not mode_series.empty:\n",
    "            mode_value = mode_series[0]\n",
    "            df[column] = df[column].fillna(mode_value)\n",
    "            console.print(f\"[bold green]Se han imputado los nulos de la columna '{column}' con la moda: {mode_value}[/bold green]\")\n",
    "        else:\n",
    "            console.print(f\"[bold red]No se pudo calcular la moda para la columna '{column}'.[/bold red]\")\n",
    "    else:\n",
    "        console.print(f\"[bold red]La estrategia '{strategy}' no es reconocida. Use 'median', 'mean' o 'mode'.[/bold red]\")\n",
    "    \n",
    "    console.print(f\"[underline white]                               \")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `convert_to_categorical(df)`\n",
    "Reduce la cardinalidad en columnas “identifier” agrupando valores poco frecuentes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich.console import Console\n",
    "import pandas as pd\n",
    "\n",
    "console = Console()\n",
    "\n",
    "def convert_to_categorical(df):\n",
    "    # Listamos las columnas originales para no iterar sobre columnas generadas por get_dummies.\n",
    "    original_columns = df.columns.tolist()\n",
    "    processed_cols = set()\n",
    "    \n",
    "    # Procesar columnas que contengan \"identifier\"\n",
    "    for col in original_columns:\n",
    "        if \"identifier\" in col.lower():\n",
    "            threshold_value = len(df) * 0.05\n",
    "            vc = df[col].value_counts()\n",
    "            top_values = vc[vc > threshold_value].index\n",
    "            # Definir un prefijo eliminando la palabra \"Identifier\" (manteniendo el resto) o usar uno por defecto.\n",
    "            prefix = col.replace(\"Identifier\", \"\").strip()\n",
    "            prefix = f\"{prefix}_\" if prefix else \"Identifier_\"\n",
    "            # Renombrar cada valor según si está en los top o no.\n",
    "            df[col] = df[col].apply(lambda x: f\"{prefix}{x}\" if x in top_values else f\"Otros{prefix.rstrip('_')}\")\n",
    "            # Aplicar One-Hot Encoding y eliminar la columna original.\n",
    "            df = pd.get_dummies(df, columns=[col], prefix=\"\", prefix_sep=\"\")\n",
    "            processed_cols.add(col)\n",
    "            console.print(f\"[bold green]Procesada columna '{col}' (basada en 'identifier') con One-Hot Encoding.[/bold green]\")\n",
    "    \n",
    "    # Procesar columnas que contengan \"version\" y que no hayan sido procesadas ya\n",
    "    for col in original_columns:\n",
    "        if \"version\" in col.lower() and col not in processed_cols:\n",
    "            threshold_value = len(df) * 0.05\n",
    "            vc = df[col].value_counts()\n",
    "            top_values = vc[vc > threshold_value].index\n",
    "            # Definir un prefijo eliminando la palabra \"Version\" o usar uno por defecto.\n",
    "            prefix = col.replace(\"Version\", \"\").strip()\n",
    "            prefix = f\"{prefix}_\" if prefix else \"Version_\"\n",
    "            df[col] = df[col].apply(lambda x: f\"{prefix}{x}\" if x in top_values else f\"Otros{prefix.rstrip('_')}\")\n",
    "            df = pd.get_dummies(df, columns=[col], prefix=\"\", prefix_sep=\"\")\n",
    "            processed_cols.add(col)\n",
    "            console.print(f\"[bold green]Procesada columna '{col}' (basada en 'version') con One-Hot Encoding.[/bold green]\")\n",
    "    \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `drop_low_correlation_columns(df, threshold=0.01)`\n",
    "Elimina las columnas numéricas (incluyendo las booleanas) que presentan una correlación muy baja con todas las demás columnas, según un umbral especificado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def drop_low_correlation_columns(df, threshold=0.01):\n",
    "    corr_matrix = df.corr()\n",
    "    low_corr_cols = []\n",
    "    \n",
    "    for col in corr_matrix.columns:\n",
    "        other_corr = corr_matrix[col].drop(labels=col)\n",
    "        if (abs(other_corr) < threshold).all():\n",
    "            low_corr_cols.append(col)\n",
    "    \n",
    "    df = df.drop(columns=low_corr_cols)\n",
    "    console.print(f\"[bold red]Columnas numéricas eliminadas por baja correlación (umbral {threshold}):[/bold red] {low_corr_cols}\")\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `show_column_statistics(df, column)`\n",
    "Muestra estadísticas descriptivas y visualizaciones básicas (histograma y boxplot) para la columna especificada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_column_statistics(df, column):\n",
    "    if column not in df.columns:\n",
    "        console.print(f\"[bold red]La columna '{column}' no existe en el DataFrame.[/bold red]\")\n",
    "        return\n",
    "\n",
    "    console.print(f\"[bold cyan]Estadísticas de la columna '{column}':[/bold cyan]\")\n",
    "    console.print(df[column].describe())\n",
    "    \n",
    "    # Histograma\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    sns.histplot(df[column].dropna(), kde=True)\n",
    "    plt.title(f\"Histograma de '{column}'\")\n",
    "    plt.xlabel(column)\n",
    "    plt.ylabel(\"Frecuencia\")\n",
    "    plt.show()\n",
    "\n",
    "    # Boxplot\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    sns.boxplot(x=df[column])\n",
    "    plt.title(f\"Boxplot de '{column}'\")\n",
    "    plt.xlabel(column)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## funcion: `plot_full_correlation_matrix(df)`\n",
    "Genera y muestra la matriz de correlación de todas las columnas numéricas del DataFrame, ajustando dinámicamente el tamaño del gráfico según el número de variables para una visualización clara."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "\n",
    "def plot_full_correlation_matrix(df):\n",
    "    df_corr = df.copy()\n",
    "    \n",
    "    cat_cols = df_corr.select_dtypes(include=[\"category\"]).columns\n",
    "    if len(cat_cols) > 0:\n",
    "        df_corr[cat_cols] = df_corr[cat_cols].apply(lambda s: s.cat.codes)\n",
    "    \n",
    "    bool_cols = df_corr.select_dtypes(include=[\"bool\"]).columns\n",
    "    if len(bool_cols) > 0:\n",
    "        df_corr[bool_cols] = df_corr[bool_cols].astype(int)\n",
    "    \n",
    "    dt_cols = df_corr.select_dtypes(include=[\"datetime64[ns]\"]).columns\n",
    "    if len(dt_cols) > 0:\n",
    "        df_corr[dt_cols] = df_corr[dt_cols].astype('int64')\n",
    "    \n",
    "    numeric_df = df_corr.select_dtypes(include=[\"number\"])\n",
    "    corr_matrix = numeric_df.corr()\n",
    "    \n",
    "    n = corr_matrix.shape[0]\n",
    "    width = max(12, n)\n",
    "    height = max(10, n)\n",
    "    \n",
    "    plt.figure(figsize=(width, height))\n",
    "    sns.heatmap(corr_matrix, annot=True, cmap=\"coolwarm\", fmt=\".2f\", square=True)\n",
    "    plt.title(\"Matriz de correlación completa\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Aplicacion de metodos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Comenzaremos eliminando columnas en las que cada valor es único lo cual se trate de índices internos que no aportan información útil."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_unique_columns(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Ahora eliminamos columnas con más del 50% de valores nulos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_columns_with_nulls(df, threshold=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Conversion a categoricas?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_to_categorical(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Eliminar filas con pocos valores nulos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_rows_with_few_nulls(df, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "> Basados en el output de nuestra funcion anterior, vamos a aplicar nuestra funcion de imputacion de nulos `fill`\n",
    "```\n",
    "| SmartScreen                                       │ 36%        │\n",
    "│ OrganizationIdentifier                            │ 31%        │\n",
    "│ SMode                                             │ 6%         │\n",
    "│ CityIdentifier                                    │ 4%         │\n",
    "│ Wdft_IsGamer                                      │ 3%         │\n",
    "│ Wdft_RegionIdentifier                             │ 3%         │\n",
    "│ Census_InternalBatteryNumberOfCharges             │ 3%         │\n",
    "│ Census_FirmwareManufacturerIdentifier             │ 2%         │\n",
    "│ Census_FirmwareVersionIdentifier                  │ 2%         │\n",
    "│ Census_IsFlightsDisabled                          │ 2%         │\n",
    "│ Census_OEMModelIdentifier                         │ 1%         │\n",
    "│ Census_OEMNameIdentifier                          │ 1%         │\n",
    "│ Firewall                                          │ 1%         │\n",
    "│ Census_TotalPhysicalRAM                           │ 1%         │\n",
    "│ Census_IsAlwaysOnAlwaysConnectedCapable           │ 1%         │\n",
    "│ Census_OSInstallLanguageIdentifier                │ 1%         │\n",
    "│ IeVerIdentifier                                   │ 1%         │\n",
    "│ Census_SystemVolumeTotalCapacity                  │ 1%         │\n",
    "│ Census_PrimaryDiskTotalCapacity                   │ 1%         │\n",
    "│ Census_InternalPrimaryDiagonalDisplaySizeInInches │ 1%         │\n",
    "│ Census_InternalPrimaryDisplayResolutionVertical   │ 1%         │\n",
    "│ Census_InternalPrimaryDisplayResolutionHorizontal │ 1%         |\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnas_a_imputar = [\n",
    "    \"SmartScreen\",\n",
    "    \"OrganizationIdentifier\",\n",
    "    \"SMode\",\n",
    "    \"CityIdentifier\",\n",
    "    \"Wdft_IsGamer\",\n",
    "    \"Wdft_RegionIdentifier\",\n",
    "    \"Census_InternalBatteryNumberOfCharges\",\n",
    "    \"Census_FirmwareManufacturerIdentifier\",\n",
    "    \"Census_FirmwareVersionIdentifier\",\n",
    "    \"Census_IsFlightsDisabled\",\n",
    "    \"Census_OEMModelIdentifier\",\n",
    "    \"Census_OEMNameIdentifier\",\n",
    "    \"Firewall\",\n",
    "    \"Census_TotalPhysicalRAM\",\n",
    "    \"Census_IsAlwaysOnAlwaysConnectedCapable\",\n",
    "    \"Census_OSInstallLanguageIdentifier\",\n",
    "    \"IeVerIdentifier\",\n",
    "    \"Census_SystemVolumeTotalCapacity\",\n",
    "    \"Census_PrimaryDiskTotalCapacity\",\n",
    "    \"Census_InternalPrimaryDiagonalDisplaySizeInInches\",\n",
    "    \"Census_InternalPrimaryDisplayResolutionVertical\",\n",
    "    \"Census_InternalPrimaryDisplayResolutionHorizontal\"\n",
    "]\n",
    "\n",
    "for col in columnas_a_imputar:\n",
    "    df = fill_nulls_in_column(df, col)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Ahora ejecutaremos el funcion que nos ayudo a sacar los nulos por columna y asi ver como nos ha quedado:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_rows_with_few_nulls(df, threshold=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Podemos ver que ahora no tenemos nulos en ninguna columna. Solo por si acaso ejecutaremos mas codigo para asegurarnos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().mean().sort_values(ascending=False) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Como podemos ver ya no tenemos mas valores nulos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aplicar_ohe(df):\n",
    "    string_cols = df.select_dtypes(include=['object']).columns.tolist()\n",
    "    \n",
    "    if not string_cols:\n",
    "        print(\"No hay columnas categóricas para codificar.\")\n",
    "        return df\n",
    "\n",
    "    # Aplicar One-Hot Encoding\n",
    "    df_ohe = pd.get_dummies(df, columns=string_cols, drop_first=True)\n",
    "    \n",
    "    return df_ohe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalizar_dataframe(df, metodo=\"minmax\"):\n",
    "    # Identificar columnas numéricas\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns.tolist()\n",
    "    \n",
    "    if not numeric_cols:\n",
    "        print(\"No hay columnas numéricas para normalizar.\")\n",
    "        return df  # Devuelve el DataFrame sin cambios si no hay columnas numéricas\n",
    "    \n",
    "    df_normalizado = df.copy()  # Copia para no modificar el original\n",
    "    \n",
    "    if metodo == \"minmax\":\n",
    "        scaler = MinMaxScaler()\n",
    "    elif metodo == \"zscore\":\n",
    "        scaler = StandardScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Método no válido. Usa 'minmax' o 'zscore'.\")\n",
    "\n",
    "    # Aplicar normalización a las columnas numéricas\n",
    "    df_normalizado[numeric_cols] = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    return df_normalizado\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = aplicar_ohe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = normalizar_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = drop_low_correlation_columns(df, threshold=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_full_correlation_matrix(df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
